{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    " # Table of Contents\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\" id=\"toc-level0\"><li><span><a href=\"http://localhost:8890/notebooks/16-unet-inception.ipynb#Load-libraries\" data-toc-modified-id=\"Load-libraries-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load libraries</a></span></li><li><span><a href=\"http://localhost:8890/notebooks/16-unet-inception.ipynb#Define-loss-functions\" data-toc-modified-id=\"Define-loss-functions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Define loss functions</a></span></li><li><span><a href=\"http://localhost:8890/notebooks/16-unet-inception.ipynb#Define-models\" data-toc-modified-id=\"Define-models-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Define models</a></span></li><li><span><a href=\"http://localhost:8890/notebooks/16-unet-inception.ipynb#Modeling\" data-toc-modified-id=\"Modeling-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Modeling</a></span></li><li><span><a href=\"http://localhost:8890/notebooks/16-unet-inception.ipynb#v2\" data-toc-modified-id=\"v2-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>v2</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:23:32.382038Z",
     "start_time": "2017-09-08T10:23:19.006734Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, BatchNormalization, AveragePooling2D\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:23:32.392477Z",
     "start_time": "2017-09-08T10:23:32.383784Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coeff(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coeff(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T07:28:44.790919Z",
     "start_time": "2017-09-08T07:28:44.297087Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D, Dense\n",
    "from keras.layers import BatchNormalization, Dropout, Flatten, Lambda\n",
    "from keras.layers.advanced_activations import ELU, LeakyReLU\n",
    "\n",
    "IMG_ROWS, IMG_COLS = 128, 128\n",
    "\n",
    "def _shortcut(_input, residual):\n",
    "    stride_width = _input._keras_shape[2] / residual._keras_shape[2]\n",
    "    stride_height = _input._keras_shape[3] / residual._keras_shape[3]\n",
    "    equal_channels = residual._keras_shape[1] == _input._keras_shape[1]\n",
    "\n",
    "    shortcut = _input\n",
    "    # 1 X 1 conv if shape is different. Else identity.\n",
    "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
    "        shortcut = Convolution2D(nb_filter=residual._keras_shape[1], nb_row=1, nb_col=1,\n",
    "                                 subsample=(stride_width, stride_height),\n",
    "                                 init=\"he_normal\", border_mode=\"valid\")(_input)\n",
    "\n",
    "    return merge([shortcut, residual], mode=\"sum\")\n",
    "\n",
    "\n",
    "def inception_block(inputs, depth, batch_mode=0, splitted=False, activation='relu'):\n",
    "    assert depth % 16 == 0\n",
    "    actv = activation == 'relu' and (lambda: LeakyReLU(0.0)) or activation == 'elu' and (lambda: ELU(1.0)) or None\n",
    "    \n",
    "    c1_1 = Convolution2D(int(depth/4), 1, 1, init='he_normal', border_mode='same')(inputs)\n",
    "    \n",
    "    c2_1 = Convolution2D(int(depth/8*3), 1, 1, init='he_normal', border_mode='same')(inputs)\n",
    "    c2_1 = actv()(c2_1)\n",
    "    if splitted:\n",
    "        c2_2 = Convolution2D(int(depth/2), 1, 3, init='he_normal', border_mode='same')(c2_1)\n",
    "        c2_2 = BatchNormalization(axis=3)(c2_2)\n",
    "        c2_2 = actv()(c2_2)\n",
    "        c2_3 = Convolution2D(int(depth/2), 3, 1, init='he_normal', border_mode='same')(c2_2)\n",
    "    else:\n",
    "        c2_3 = Convolution2D(int(depth/2), 3, 3, init='he_normal', border_mode='same')(c2_1)\n",
    "    \n",
    "    c3_1 = Convolution2D(int(depth/16), 1, 1, init='he_normal', border_mode='same')(inputs)\n",
    "    #missed batch norm\n",
    "    c3_1 = actv()(c3_1)\n",
    "    if splitted:\n",
    "        c3_2 = Convolution2D(int(depth/8), 1, 5, init='he_normal', border_mode='same')(c3_1)\n",
    "        c3_2 = BatchNormalization(axis=3)(c3_2)\n",
    "        c3_2 = actv()(c3_2)\n",
    "        c3_3 = Convolution2D(int(depth/8), 5, 1, init='he_normal', border_mode='same')(c3_2)\n",
    "    else:\n",
    "        c3_3 = Convolution2D(int(depth/8), 5, 5, init='he_normal', border_mode='same')(c3_1)\n",
    "    \n",
    "    p4_1 = MaxPooling2D(pool_size=(3,3), strides=(1,1), border_mode='same')(inputs)\n",
    "    c4_2 = Convolution2D(int(depth/8), 1, 1, init='he_normal', border_mode='same')(p4_1)\n",
    "    \n",
    "    res = merge([c1_1, c2_3, c3_3, c4_2], mode='concat', concat_axis=3)\n",
    "    res = BatchNormalization(axis=3)(res)\n",
    "    res = actv()(res)\n",
    "    return res\n",
    "    \n",
    "\n",
    "def rblock(inputs, num, depth, scale=0.1):    \n",
    "    residual = Convolution2D(depth, num, num, border_mode='same')(inputs)\n",
    "    residual = BatchNormalization(axis=3)(residual)\n",
    "    residual = Lambda(lambda x: x*scale)(residual)\n",
    "    res = _shortcut(inputs, residual)\n",
    "    return ELU()(res) \n",
    "    \n",
    "\n",
    "def NConvolution2D(nb_filter, nb_row, nb_col, border_mode='same', subsample=(1, 1)):\n",
    "    def f(_input):\n",
    "        conv = Convolution2D(nb_filter=nb_filter, nb_row=nb_row, nb_col=nb_col, subsample=subsample,\n",
    "                              border_mode=border_mode)(_input)\n",
    "        norm = BatchNormalization(axis=3)(conv)\n",
    "        return ELU()(norm)\n",
    "\n",
    "    return f\n",
    "\n",
    "def BNA(_input):\n",
    "    inputs_norm = BatchNormalization(axis=3)(_input)\n",
    "    return ELU()(inputs_norm)\n",
    "\n",
    "def reduction_a(inputs, k=64, l=64, m=96, n=96):\n",
    "    \"35x35 -> 17x17\"\n",
    "    inputs_norm = BNA(inputs)\n",
    "    pool1 = MaxPooling2D((3,3), strides=(2,2), border_mode='same')(inputs_norm)\n",
    "    \n",
    "    conv2 = Convolution2D(n, 3, 3, subsample=(2,2), border_mode='same')(inputs_norm)\n",
    "    \n",
    "    conv3_1 = NConvolution2D(k, 1, 1, subsample=(1,1), border_mode='same')(inputs_norm)\n",
    "    conv3_2 = NConvolution2D(l, 3, 3, subsample=(1,1), border_mode='same')(conv3_1)\n",
    "    conv3_2 = Convolution2D(m, 3, 3, subsample=(2,2), border_mode='same')(conv3_2)\n",
    "    \n",
    "    res = merge([pool1, conv2, conv3_2], mode='concat', concat_axis=3)\n",
    "    return res\n",
    "\n",
    "\n",
    "def reduction_b(inputs):\n",
    "    \"17x17 -> 8x8\"\n",
    "    inputs_norm = BNA(inputs)\n",
    "    pool1 = MaxPooling2D((3,3), strides=(2,2), border_mode='same')(inputs_norm)\n",
    "    #\n",
    "    conv2_1 = NConvolution2D(64, 1, 1, subsample=(1,1), border_mode='same')(inputs_norm)\n",
    "    conv2_2 = Convolution2D(96, 3, 3, subsample=(2,2), border_mode='same')(conv2_1)\n",
    "    #\n",
    "    conv3_1 = NConvolution2D(64, 1, 1, subsample=(1,1), border_mode='same')(inputs_norm)\n",
    "    conv3_2 = Convolution2D(72, 3, 3, subsample=(2,2), border_mode='same')(conv3_1)\n",
    "    #\n",
    "    conv4_1 = NConvolution2D(64, 1, 1, subsample=(1,1), border_mode='same')(inputs_norm)\n",
    "    conv4_2 = NConvolution2D(72, 3, 3, subsample=(1,1), border_mode='same')(conv4_1)\n",
    "    conv4_3 = Convolution2D(80, 3, 3, subsample=(2,2), border_mode='same')(conv4_2)\n",
    "    #\n",
    "    res = merge([pool1, conv2_2, conv3_2, conv4_3], mode='concat', concat_axis=3)\n",
    "    return res\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def get_unet_inception_2head(optimizer):\n",
    "    splitted = True\n",
    "    act = 'elu'\n",
    "    \n",
    "    inputs = Input((IMG_ROWS, IMG_COLS, 3), name='main_input')\n",
    "    conv1 = inception_block(inputs, 32, batch_mode=2, splitted=splitted, activation=act)\n",
    "    #conv1 = inception_block(conv1, 32, batch_mode=2, splitted=splitted, activation=act)\n",
    "    \n",
    "    #pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    pool1 = NConvolution2D(32, 3, 3, border_mode='same', subsample=(2,2))(conv1)\n",
    "    pool1 = Dropout(0.5)(pool1)\n",
    "    \n",
    "    conv2 = inception_block(pool1, 64, batch_mode=2, splitted=splitted, activation=act)\n",
    "    #pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    pool2 = NConvolution2D(64, 3, 3, border_mode='same', subsample=(2,2))(conv2)\n",
    "    pool2 = Dropout(0.5)(pool2)\n",
    "    \n",
    "    conv3 = inception_block(pool2, 128, batch_mode=2, splitted=splitted, activation=act)\n",
    "    #pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    pool3 = NConvolution2D(128, 3, 3, border_mode='same', subsample=(2,2))(conv3)\n",
    "    pool3 = Dropout(0.5)(pool3)\n",
    "     \n",
    "    conv4 = inception_block(pool3, 256, batch_mode=2, splitted=splitted, activation=act)\n",
    "    #pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    pool4 = NConvolution2D(256, 3, 3, border_mode='same', subsample=(2,2))(conv4)\n",
    "    pool4 = Dropout(0.5)(pool4)\n",
    "    \n",
    "    conv5 = inception_block(pool4, 512, batch_mode=2, splitted=splitted, activation=act)\n",
    "    #conv5 = inception_block(conv5, 512, batch_mode=2, splitted=splitted, activation=act)\n",
    "    conv5 = Dropout(0.5)(conv5)\n",
    "    \n",
    "    after_conv4 = rblock(conv4, 1, 256)\n",
    "    up6 = merge([UpSampling2D(size=(2, 2))(conv5), after_conv4], mode='concat', concat_axis=3)\n",
    "    conv6 = inception_block(up6, 256, batch_mode=2, splitted=splitted, activation=act)\n",
    "    conv6 = Dropout(0.5)(conv6)\n",
    "    \n",
    "    after_conv3 = rblock(conv3, 1, 128)\n",
    "    up7 = merge([UpSampling2D(size=(2, 2))(conv6), after_conv3], mode='concat', concat_axis=3)\n",
    "    conv7 = inception_block(up7, 128, batch_mode=2, splitted=splitted, activation=act)\n",
    "    conv7 = Dropout(0.5)(conv7)\n",
    "    \n",
    "    after_conv2 = rblock(conv2, 1, 64)\n",
    "    up8 = merge([UpSampling2D(size=(2, 2))(conv7), after_conv2], mode='concat', concat_axis=3)\n",
    "    conv8 = inception_block(up8, 64, batch_mode=2, splitted=splitted, activation=act)\n",
    "    conv8 = Dropout(0.5)(conv8)\n",
    "    \n",
    "    after_conv1 = rblock(conv1, 1, 32)\n",
    "    up9 = merge([UpSampling2D(size=(2, 2))(conv8), after_conv1], mode='concat', concat_axis=3)\n",
    "    conv9 = inception_block(up9, 32, batch_mode=2, splitted=splitted, activation=act)\n",
    "    #conv9 = inception_block(conv9, 32, batch_mode=2, splitted=splitted, activation=act)\n",
    "    conv9 = Dropout(0.5)(conv9)\n",
    "\n",
    "    conv10 = Convolution2D(1, 1, 1, init='he_normal', activation='sigmoid', name='main_output')(conv9)\n",
    "    #print conv10._keras_shape\n",
    "\n",
    "    model = Model(input=inputs, output=conv10)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=bce_dice_loss,\n",
    "                  metrics=[dice_coeff])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "get_unet = get_unet_inception_2head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T07:28:47.087370Z",
     "start_time": "2017-09-08T07:28:44.799888Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (1, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (1, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 3), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2, (1, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(4, (1, 5), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(4, (5, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:51: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding=\"same\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:52: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(4, (1, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:54: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:71: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), filters=32, strides=(2, 2), padding=\"same\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (1, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 3), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(4, (1, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (1, 5), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (5, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:52: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (1, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:71: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), filters=64, strides=(2, 2), padding=\"same\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (1, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 3), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (1, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 5), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (5, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:52: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:71: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), filters=128, strides=(2, 2), padding=\"same\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (1, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 3), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 5), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (5, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:52: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:71: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), filters=256, strides=(2, 2), padding=\"same\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (1, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 3), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 5), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:52: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), padding=\"same\", kernel_initializer=\"he_normal\")`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:61: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), padding=\"same\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:149: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:61: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), padding=\"same\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:154: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:61: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), padding=\"same\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:159: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:61: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), padding=\"same\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:164: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:169: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (1, 1), activation=\"sigmoid\", name=\"main_output\", kernel_initializer=\"he_normal\")`\n",
      "/home/sainath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:172: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"ma..., outputs=Tensor(\"ma...)`\n"
     ]
    }
   ],
   "source": [
    "model = get_unet(Adam(lr=1e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T07:28:47.100912Z",
     "start_time": "2017-09-08T07:28:47.097333Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size = 128\n",
    "max_epochs = 50\n",
    "train_batch_size = 16\n",
    "val_batch_size=32\n",
    "orig_width = 1918\n",
    "orig_height= 1280\n",
    "threshold  = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T07:28:48.631403Z",
     "start_time": "2017-09-08T07:28:47.110784Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train_masks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T07:28:48.670426Z",
     "start_time": "2017-09-08T07:28:48.656760Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>rle_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00087a6bd4dc_01.jpg</td>\n",
       "      <td>879386 40 881253 141 883140 205 885009 17 8850...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00087a6bd4dc_02.jpg</td>\n",
       "      <td>873779 4 875695 7 877612 9 879528 12 881267 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00087a6bd4dc_03.jpg</td>\n",
       "      <td>864300 9 866217 13 868134 15 870051 16 871969 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00087a6bd4dc_04.jpg</td>\n",
       "      <td>879735 20 881650 26 883315 92 883564 30 885208...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00087a6bd4dc_05.jpg</td>\n",
       "      <td>883365 74 883638 28 885262 119 885550 34 88716...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   img                                           rle_mask\n",
       "0  00087a6bd4dc_01.jpg  879386 40 881253 141 883140 205 885009 17 8850...\n",
       "1  00087a6bd4dc_02.jpg  873779 4 875695 7 877612 9 879528 12 881267 15...\n",
       "2  00087a6bd4dc_03.jpg  864300 9 866217 13 868134 15 870051 16 871969 ...\n",
       "3  00087a6bd4dc_04.jpg  879735 20 881650 26 883315 92 883564 30 885208...\n",
       "4  00087a6bd4dc_05.jpg  883365 74 883638 28 885262 119 885550 34 88716..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T07:28:48.718631Z",
     "start_time": "2017-09-08T07:28:48.693987Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids_train = df_train['img'].map(lambda s: s.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T07:28:48.779902Z",
     "start_time": "2017-09-08T07:28:48.747108Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids_train_split, ids_valid_split = train_test_split(ids_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:25:08.154739Z",
     "start_time": "2017-09-08T10:25:08.143166Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomHueSaturationValue(image, hue_shift_limit=(-180, 180),\n",
    "                             sat_shift_limit=(-255, 255),\n",
    "                             val_shift_limit=(-255, 255), u=0.5):\n",
    "    if np.random.random() < u:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        h, s, v = cv2.split(image)\n",
    "        hue_shift = np.random.uniform(hue_shift_limit[0], hue_shift_limit[1])\n",
    "        h = cv2.add(h, hue_shift)\n",
    "        sat_shift = np.random.uniform(sat_shift_limit[0], sat_shift_limit[1])\n",
    "        s = cv2.add(s, sat_shift)\n",
    "        val_shift = np.random.uniform(val_shift_limit[0], val_shift_limit[1])\n",
    "        v = cv2.add(v, val_shift)\n",
    "        image = cv2.merge((h, s, v))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:25:08.712940Z",
     "start_time": "2017-09-08T10:25:08.685819Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomShiftScaleRotate(image, mask,\n",
    "                           shift_limit=(-0.0625, 0.0625),\n",
    "                           scale_limit=(-0.1, 0.1),\n",
    "                           rotate_limit=(-45, 45), aspect_limit=(0, 0),\n",
    "                           borderMode=cv2.BORDER_CONSTANT, u=0.5):\n",
    "    if np.random.random() < u:\n",
    "        height, width, channel = image.shape\n",
    "\n",
    "        angle = np.random.uniform(rotate_limit[0], rotate_limit[1])  # degree\n",
    "        scale = np.random.uniform(1 + scale_limit[0], 1 + scale_limit[1])\n",
    "        aspect = np.random.uniform(1 + aspect_limit[0], 1 + aspect_limit[1])\n",
    "        sx = scale * aspect / (aspect ** 0.5)\n",
    "        sy = scale / (aspect ** 0.5)\n",
    "        dx = round(np.random.uniform(shift_limit[0], shift_limit[1]) * width)\n",
    "        dy = round(np.random.uniform(shift_limit[0], shift_limit[1]) * height)\n",
    "\n",
    "        cc = np.math.cos(angle / 180 * np.math.pi) * sx\n",
    "        ss = np.math.sin(angle / 180 * np.math.pi) * sy\n",
    "        rotate_matrix = np.array([[cc, -ss], [ss, cc]])\n",
    "\n",
    "        box0 = np.array([[0, 0], [width, 0], [width, height], [0, height], ])\n",
    "        box1 = box0 - np.array([width / 2, height / 2])\n",
    "        box1 = np.dot(box1, rotate_matrix.T) + np.array([width / 2 + dx, height / 2 + dy])\n",
    "\n",
    "        box0 = box0.astype(np.float32)\n",
    "        box1 = box1.astype(np.float32)\n",
    "        mat = cv2.getPerspectiveTransform(box0, box1)\n",
    "        image = cv2.warpPerspective(image, mat, (width, height), flags=cv2.INTER_LINEAR, borderMode=borderMode,\n",
    "                                    borderValue=(\n",
    "                                        0, 0,\n",
    "                                        0,))\n",
    "        mask = cv2.warpPerspective(mask, mat, (width, height), flags=cv2.INTER_LINEAR, borderMode=borderMode,\n",
    "                                   borderValue=(\n",
    "                                       0, 0,\n",
    "                                       0,))\n",
    "\n",
    "    return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:25:09.157553Z",
     "start_time": "2017-09-08T10:25:09.153607Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomHorizontalFlip(image, mask, u=0.5):\n",
    "    if np.random.random() < u:\n",
    "        image = cv2.flip(image, 1)\n",
    "        mask = cv2.flip(mask, 1)\n",
    "\n",
    "    return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T07:33:44.089347Z",
     "start_time": "2017-09-08T07:28:48.974183Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_imgs  = {}\n",
    "all_masks = {}\n",
    "for id in ids_train:\n",
    "    img  = cv2.imread('data/train/{}.jpg'.format(id))\n",
    "    img  = cv2.resize(img, (input_size, input_size))\n",
    "    mask = cv2.imread('data/train_masks/{}_mask.png'.format(id), cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.resize(mask, (input_size, input_size))\n",
    "    all_imgs[id]  = img\n",
    "    all_masks[id] = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:28:10.761197Z",
     "start_time": "2017-09-08T10:28:10.758348Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:28:10.777529Z",
     "start_time": "2017-09-08T10:28:10.762841Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_generator(train_batch_size):\n",
    "    while True:\n",
    "        this_ids_train_split = random.sample(list(ids_train_split), len(list(ids_train_split)))\n",
    "        for start in range(0, len(ids_train_split), train_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            \n",
    "            end = min(start + train_batch_size, len(ids_train_split))\n",
    "            ids_train_batch = this_ids_train_split[start:end]\n",
    "            \n",
    "            for id in ids_train_batch:\n",
    "                img  = all_imgs[id]\n",
    "                mask = all_masks[id]\n",
    "                img = randomHueSaturationValue(img,\n",
    "                                               hue_shift_limit=(-50, 50),\n",
    "                                               sat_shift_limit=(-5, 5),\n",
    "                                               val_shift_limit=(-15, 15))\n",
    "                img, mask = randomShiftScaleRotate(img, mask,\n",
    "                                                   shift_limit=(-0.0625, 0.0625),\n",
    "                                                   scale_limit=(-0.1, 0.1),\n",
    "                                                   rotate_limit=(-0, 0))\n",
    "                img, mask = randomHorizontalFlip(img, mask)\n",
    "                mask = np.expand_dims(mask, axis=2)\n",
    "                x_batch.append(img)\n",
    "                y_batch.append(mask)\n",
    "            x_batch = np.array(x_batch, np.float32) / 255\n",
    "            y_batch = np.array(y_batch, np.float32) / 255\n",
    "            yield x_batch, y_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:28:10.788551Z",
     "start_time": "2017-09-08T10:28:10.779090Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def valid_generator(val_batch_size):\n",
    "    while True:\n",
    "        for start in range(0, len(ids_valid_split), val_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + val_batch_size, len(ids_valid_split))\n",
    "            ids_valid_batch = ids_valid_split[start:end]\n",
    "            for id in ids_valid_batch.values:\n",
    "                img  = all_imgs[id]\n",
    "                mask = all_masks[id]\n",
    "                mask = np.expand_dims(mask, axis=2)\n",
    "                x_batch.append(img)\n",
    "                y_batch.append(mask)\n",
    "            x_batch = np.array(x_batch, np.float32) / 255\n",
    "            y_batch = np.array(y_batch, np.float32) / 255\n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-08T05:27:16.661Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "208s - loss: 1.2588 - dice_coeff: 0.4351 - val_loss: 1.1301 - val_dice_coeff: 0.3091\n",
      "Epoch 2/50\n",
      "192s - loss: 0.9890 - dice_coeff: 0.5376 - val_loss: 1.1081 - val_dice_coeff: 0.3145\n",
      "Epoch 3/50\n",
      "192s - loss: 0.8052 - dice_coeff: 0.6017 - val_loss: 0.8988 - val_dice_coeff: 0.4504\n",
      "Epoch 4/50\n",
      "192s - loss: 0.6790 - dice_coeff: 0.6488 - val_loss: 0.8308 - val_dice_coeff: 0.4970\n",
      "Epoch 5/50\n",
      "192s - loss: 0.5943 - dice_coeff: 0.6836 - val_loss: 0.7180 - val_dice_coeff: 0.5706\n",
      "Epoch 6/50\n",
      "192s - loss: 0.5322 - dice_coeff: 0.7107 - val_loss: 0.6272 - val_dice_coeff: 0.6281\n",
      "Epoch 7/50\n",
      "192s - loss: 0.4846 - dice_coeff: 0.7328 - val_loss: 0.5708 - val_dice_coeff: 0.6643\n",
      "Epoch 8/50\n",
      "192s - loss: 0.4419 - dice_coeff: 0.7536 - val_loss: 0.5256 - val_dice_coeff: 0.6938\n",
      "Epoch 9/50\n",
      "192s - loss: 0.4078 - dice_coeff: 0.7710 - val_loss: 0.4832 - val_dice_coeff: 0.7208\n",
      "Epoch 10/50\n",
      "192s - loss: 0.3791 - dice_coeff: 0.7851 - val_loss: 0.4303 - val_dice_coeff: 0.7525\n",
      "Epoch 11/50\n",
      "192s - loss: 0.3553 - dice_coeff: 0.7979 - val_loss: 0.4288 - val_dice_coeff: 0.7547\n",
      "Epoch 12/50\n",
      "192s - loss: 0.3357 - dice_coeff: 0.8081 - val_loss: 0.3868 - val_dice_coeff: 0.7802\n",
      "Epoch 13/50\n",
      "192s - loss: 0.3188 - dice_coeff: 0.8173 - val_loss: 0.3836 - val_dice_coeff: 0.7828\n",
      "Epoch 14/50\n",
      "194s - loss: 0.3038 - dice_coeff: 0.8253 - val_loss: 0.3647 - val_dice_coeff: 0.7948\n",
      "Epoch 15/50\n",
      "192s - loss: 0.2898 - dice_coeff: 0.8333 - val_loss: 0.3450 - val_dice_coeff: 0.8059\n",
      "Epoch 16/50\n",
      "192s - loss: 0.2781 - dice_coeff: 0.8397 - val_loss: 0.3394 - val_dice_coeff: 0.8105\n",
      "Epoch 17/50\n",
      "192s - loss: 0.2685 - dice_coeff: 0.8452 - val_loss: 0.3184 - val_dice_coeff: 0.8220\n",
      "Epoch 18/50\n",
      "192s - loss: 0.2573 - dice_coeff: 0.8516 - val_loss: 0.3079 - val_dice_coeff: 0.8286\n",
      "Epoch 19/50\n",
      "192s - loss: 0.2479 - dice_coeff: 0.8569 - val_loss: 0.2985 - val_dice_coeff: 0.8343\n",
      "Epoch 20/50\n",
      "192s - loss: 0.2394 - dice_coeff: 0.8618 - val_loss: 0.2945 - val_dice_coeff: 0.8375\n",
      "Epoch 21/50\n",
      "192s - loss: 0.2325 - dice_coeff: 0.8660 - val_loss: 0.2899 - val_dice_coeff: 0.8416\n",
      "Epoch 22/50\n",
      "192s - loss: 0.2237 - dice_coeff: 0.8710 - val_loss: 0.2702 - val_dice_coeff: 0.8521\n",
      "Epoch 23/50\n",
      "192s - loss: 0.2159 - dice_coeff: 0.8757 - val_loss: 0.2778 - val_dice_coeff: 0.8494\n",
      "Epoch 24/50\n",
      "192s - loss: 0.2117 - dice_coeff: 0.8784 - val_loss: 0.2773 - val_dice_coeff: 0.8511\n",
      "Epoch 25/50\n",
      "192s - loss: 0.2031 - dice_coeff: 0.8831 - val_loss: 0.2607 - val_dice_coeff: 0.8595\n",
      "Epoch 26/50\n",
      "192s - loss: 0.1976 - dice_coeff: 0.8865 - val_loss: 0.2579 - val_dice_coeff: 0.8617\n",
      "Epoch 27/50\n",
      "192s - loss: 0.1913 - dice_coeff: 0.8902 - val_loss: 0.2490 - val_dice_coeff: 0.8670\n",
      "Epoch 28/50\n",
      "192s - loss: 0.1858 - dice_coeff: 0.8934 - val_loss: 0.2454 - val_dice_coeff: 0.8697\n",
      "Epoch 29/50\n",
      "192s - loss: 0.1805 - dice_coeff: 0.8967 - val_loss: 0.2395 - val_dice_coeff: 0.8732\n",
      "Epoch 30/50\n",
      "192s - loss: 0.1753 - dice_coeff: 0.8998 - val_loss: 0.2451 - val_dice_coeff: 0.8719\n",
      "Epoch 31/50\n",
      "192s - loss: 0.1714 - dice_coeff: 0.9023 - val_loss: 0.2342 - val_dice_coeff: 0.8775\n",
      "Epoch 32/50\n",
      "192s - loss: 0.1661 - dice_coeff: 0.9056 - val_loss: 0.2204 - val_dice_coeff: 0.8850\n",
      "Epoch 33/50\n",
      "192s - loss: 0.1626 - dice_coeff: 0.9077 - val_loss: 0.2188 - val_dice_coeff: 0.8861\n",
      "Epoch 34/50\n",
      "192s - loss: 0.1579 - dice_coeff: 0.9106 - val_loss: 0.2042 - val_dice_coeff: 0.8934\n",
      "Epoch 35/50\n",
      "192s - loss: 0.1542 - dice_coeff: 0.9128 - val_loss: 0.2067 - val_dice_coeff: 0.8929\n",
      "Epoch 36/50\n"
     ]
    }
   ],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_dice_coeff',\n",
    "                           patience=8,\n",
    "                           verbose=1,\n",
    "                           min_delta=1e-4,\n",
    "                           mode='max'),\n",
    "             ReduceLROnPlateau(monitor='val_dice_coeff',\n",
    "                               factor=0.1,\n",
    "                               patience=4,\n",
    "                               verbose=1,\n",
    "                               epsilon=1e-4,\n",
    "                               mode='max'),\n",
    "             ModelCheckpoint(monitor='val_dice_coeff',\n",
    "                             filepath='weights/unet-inception-128.hdf5',\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             mode='max')]\n",
    "\n",
    "history = model.fit_generator(generator=train_generator(train_batch_size),\n",
    "                    steps_per_epoch=np.ceil(float(len(ids_train_split)) / float(train_batch_size)),\n",
    "                    epochs=max_epochs,\n",
    "                    verbose=2,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=valid_generator(val_batch_size),\n",
    "                    validation_steps=np.ceil(float(len(ids_valid_split)) / float(val_batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T07:35:11.053530Z",
     "start_time": "2017-09-08T07:35:07.838726Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('./weights/unet-inception-128.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T08:59:42.164243Z",
     "start_time": "2017-09-08T07:35:29.673220Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "139s - loss: 0.1539 - dice_coeff: 0.9131 - val_loss: 0.2070 - val_dice_coeff: 0.8934\n",
      "Epoch 2/50\n",
      "131s - loss: 0.1496 - dice_coeff: 0.9156 - val_loss: 0.2055 - val_dice_coeff: 0.8945\n",
      "Epoch 3/50\n",
      "132s - loss: 0.1458 - dice_coeff: 0.9181 - val_loss: 0.1965 - val_dice_coeff: 0.8996\n",
      "Epoch 4/50\n",
      "132s - loss: 0.1418 - dice_coeff: 0.9204 - val_loss: 0.1937 - val_dice_coeff: 0.9013\n",
      "Epoch 5/50\n",
      "132s - loss: 0.1387 - dice_coeff: 0.9223 - val_loss: 0.1989 - val_dice_coeff: 0.8996\n",
      "Epoch 6/50\n",
      "132s - loss: 0.1360 - dice_coeff: 0.9243 - val_loss: 0.1869 - val_dice_coeff: 0.9056\n",
      "Epoch 7/50\n",
      "132s - loss: 0.1320 - dice_coeff: 0.9265 - val_loss: 0.1746 - val_dice_coeff: 0.9115\n",
      "Epoch 8/50\n",
      "132s - loss: 0.1296 - dice_coeff: 0.9282 - val_loss: 0.1777 - val_dice_coeff: 0.9107\n",
      "Epoch 9/50\n",
      "132s - loss: 0.1265 - dice_coeff: 0.9299 - val_loss: 0.1771 - val_dice_coeff: 0.9114\n",
      "Epoch 10/50\n",
      "132s - loss: 0.1233 - dice_coeff: 0.9318 - val_loss: 0.1671 - val_dice_coeff: 0.9164\n",
      "Epoch 11/50\n",
      "132s - loss: 0.1218 - dice_coeff: 0.9330 - val_loss: 0.1677 - val_dice_coeff: 0.9166\n",
      "Epoch 12/50\n",
      "132s - loss: 0.1192 - dice_coeff: 0.9345 - val_loss: 0.1596 - val_dice_coeff: 0.9203\n",
      "Epoch 13/50\n",
      "132s - loss: 0.1172 - dice_coeff: 0.9359 - val_loss: 0.1582 - val_dice_coeff: 0.9215\n",
      "Epoch 14/50\n",
      "132s - loss: 0.1146 - dice_coeff: 0.9374 - val_loss: 0.1534 - val_dice_coeff: 0.9238\n",
      "Epoch 15/50\n",
      "132s - loss: 0.1131 - dice_coeff: 0.9384 - val_loss: 0.1559 - val_dice_coeff: 0.9231\n",
      "Epoch 16/50\n",
      "132s - loss: 0.1107 - dice_coeff: 0.9397 - val_loss: 0.1549 - val_dice_coeff: 0.9239\n",
      "Epoch 17/50\n",
      "132s - loss: 0.1094 - dice_coeff: 0.9408 - val_loss: 0.1484 - val_dice_coeff: 0.9271\n",
      "Epoch 18/50\n",
      "132s - loss: 0.1080 - dice_coeff: 0.9417 - val_loss: 0.1480 - val_dice_coeff: 0.9274\n",
      "Epoch 19/50\n",
      "132s - loss: 0.1059 - dice_coeff: 0.9429 - val_loss: 0.1439 - val_dice_coeff: 0.9295\n",
      "Epoch 20/50\n",
      "132s - loss: 0.1041 - dice_coeff: 0.9438 - val_loss: 0.1332 - val_dice_coeff: 0.9342\n",
      "Epoch 21/50\n",
      "132s - loss: 0.1030 - dice_coeff: 0.9447 - val_loss: 0.1509 - val_dice_coeff: 0.9270\n",
      "Epoch 22/50\n",
      "132s - loss: 0.1014 - dice_coeff: 0.9457 - val_loss: 0.1335 - val_dice_coeff: 0.9345\n",
      "Epoch 23/50\n",
      "132s - loss: 0.0997 - dice_coeff: 0.9467 - val_loss: 0.1392 - val_dice_coeff: 0.9324\n",
      "Epoch 24/50\n",
      "132s - loss: 0.0986 - dice_coeff: 0.9474 - val_loss: 0.1287 - val_dice_coeff: 0.9370\n",
      "Epoch 25/50\n",
      "132s - loss: 0.0972 - dice_coeff: 0.9483 - val_loss: 0.1267 - val_dice_coeff: 0.9381\n",
      "Epoch 26/50\n",
      "132s - loss: 0.0955 - dice_coeff: 0.9492 - val_loss: 0.1244 - val_dice_coeff: 0.9394\n",
      "Epoch 27/50\n",
      "132s - loss: 0.0944 - dice_coeff: 0.9499 - val_loss: 0.1254 - val_dice_coeff: 0.9392\n",
      "Epoch 28/50\n",
      "132s - loss: 0.0930 - dice_coeff: 0.9508 - val_loss: 0.1359 - val_dice_coeff: 0.9349\n",
      "Epoch 29/50\n",
      "132s - loss: 0.0925 - dice_coeff: 0.9512 - val_loss: 0.1166 - val_dice_coeff: 0.9431\n",
      "Epoch 30/50\n",
      "132s - loss: 0.0914 - dice_coeff: 0.9519 - val_loss: 0.1205 - val_dice_coeff: 0.9417\n",
      "Epoch 31/50\n",
      "132s - loss: 0.0898 - dice_coeff: 0.9528 - val_loss: 0.1225 - val_dice_coeff: 0.9411\n",
      "Epoch 32/50\n",
      "132s - loss: 0.0891 - dice_coeff: 0.9532 - val_loss: 0.1192 - val_dice_coeff: 0.9427\n",
      "Epoch 33/50\n",
      "132s - loss: 0.0887 - dice_coeff: 0.9537 - val_loss: 0.1219 - val_dice_coeff: 0.9415\n",
      "Epoch 34/50\n",
      "\n",
      "Epoch 00033: reducing learning rate to 9.999999747378752e-07.\n",
      "132s - loss: 0.0867 - dice_coeff: 0.9546 - val_loss: 0.1240 - val_dice_coeff: 0.9409\n",
      "Epoch 35/50\n",
      "132s - loss: 0.0868 - dice_coeff: 0.9547 - val_loss: 0.1193 - val_dice_coeff: 0.9428\n",
      "Epoch 36/50\n",
      "132s - loss: 0.0864 - dice_coeff: 0.9549 - val_loss: 0.1194 - val_dice_coeff: 0.9428\n",
      "Epoch 37/50\n",
      "132s - loss: 0.0862 - dice_coeff: 0.9549 - val_loss: 0.1197 - val_dice_coeff: 0.9426\n",
      "Epoch 38/50\n",
      "\n",
      "Epoch 00037: reducing learning rate to 9.999999974752428e-08.\n",
      "132s - loss: 0.0864 - dice_coeff: 0.9549 - val_loss: 0.1201 - val_dice_coeff: 0.9425\n",
      "Epoch 00037: early stopping\n"
     ]
    }
   ],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_dice_coeff',\n",
    "                           patience=8,\n",
    "                           verbose=1,\n",
    "                           min_delta=1e-4,\n",
    "                           mode='max'),\n",
    "             ReduceLROnPlateau(monitor='val_dice_coeff',\n",
    "                               factor=0.1,\n",
    "                               patience=4,\n",
    "                               verbose=1,\n",
    "                               epsilon=1e-4,\n",
    "                               mode='max'),\n",
    "             ModelCheckpoint(monitor='val_dice_coeff',\n",
    "                             filepath='weights/unet-inception-128.hdf5',\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             mode='max')]\n",
    "\n",
    "history = model.fit_generator(generator=train_generator(train_batch_size),\n",
    "                    steps_per_epoch=np.ceil(float(len(ids_train_split)) / float(train_batch_size)),\n",
    "                    epochs=max_epochs,\n",
    "                    verbose=2,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=valid_generator(val_batch_size),\n",
    "                    validation_steps=np.ceil(float(len(ids_valid_split)) / float(val_batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T09:00:21.548381Z",
     "start_time": "2017-09-08T09:00:21.541062Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dice_coeff': [0.91305642520473396,\n",
       "  0.91554450253596764,\n",
       "  0.91804631673147408,\n",
       "  0.92046436806568643,\n",
       "  0.92232778283243388,\n",
       "  0.92428327968723945,\n",
       "  0.92652074072226265,\n",
       "  0.92815641823799078,\n",
       "  0.92984956218803838,\n",
       "  0.93176751886597431,\n",
       "  0.93295332664939634,\n",
       "  0.93453360623165194,\n",
       "  0.93589913030807159,\n",
       "  0.93733690063256303,\n",
       "  0.93836108657007433,\n",
       "  0.9397426873518735,\n",
       "  0.94075169097586409,\n",
       "  0.94171554523838241,\n",
       "  0.94288925254667122,\n",
       "  0.94380051820225441,\n",
       "  0.94473870313138286,\n",
       "  0.94570001773810797,\n",
       "  0.94670223026955158,\n",
       "  0.94737135631739366,\n",
       "  0.9482602834408641,\n",
       "  0.94918990864507691,\n",
       "  0.94993915809753193,\n",
       "  0.95077761036758046,\n",
       "  0.95121461759328252,\n",
       "  0.95185924522413956,\n",
       "  0.9527948460063419,\n",
       "  0.95322414967586133,\n",
       "  0.95365553449940033,\n",
       "  0.95463427287647706,\n",
       "  0.95467898125144712,\n",
       "  0.95487894534478901,\n",
       "  0.95488508465249067,\n",
       "  0.95490348257069502],\n",
       " 'loss': [0.15395652139216148,\n",
       "  0.14959642302784931,\n",
       "  0.14577361646975581,\n",
       "  0.14180872548710216,\n",
       "  0.13873151090426292,\n",
       "  0.13596915117938629,\n",
       "  0.13200604017888007,\n",
       "  0.12956865169199444,\n",
       "  0.1265421168663578,\n",
       "  0.12323231669257255,\n",
       "  0.12188111836552913,\n",
       "  0.11910779433695631,\n",
       "  0.11723425015624091,\n",
       "  0.11463572359495139,\n",
       "  0.11316064981336382,\n",
       "  0.11069604635824443,\n",
       "  0.10936394168718441,\n",
       "  0.10790996282780199,\n",
       "  0.10592826620952503,\n",
       "  0.10412107119908789,\n",
       "  0.10297270348382523,\n",
       "  0.10140069188957425,\n",
       "  0.099686921063892958,\n",
       "  0.098653468592161037,\n",
       "  0.097192074903984918,\n",
       "  0.095524623623937002,\n",
       "  0.094445910507982428,\n",
       "  0.093023806231906425,\n",
       "  0.092517998075016594,\n",
       "  0.091418699916516244,\n",
       "  0.089772512051631545,\n",
       "  0.089096846180700254,\n",
       "  0.088724448522713023,\n",
       "  0.086646193932256768,\n",
       "  0.086769032244014499,\n",
       "  0.086311023263146311,\n",
       "  0.086261155831579492,\n",
       "  0.086421916218296022],\n",
       " 'lr': [9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  9.9999997e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06,\n",
       "  1e-06],\n",
       " 'val_dice_coeff': [0.8933765365941585,\n",
       "  0.8945479599103946,\n",
       "  0.8996087696791164,\n",
       "  0.90134870385374211,\n",
       "  0.89956024201305063,\n",
       "  0.90555753665729211,\n",
       "  0.91153906522893247,\n",
       "  0.91067750737334519,\n",
       "  0.91138062132833519,\n",
       "  0.91636046538886951,\n",
       "  0.91660813381255024,\n",
       "  0.92034526423995766,\n",
       "  0.92149726358518624,\n",
       "  0.92378008295370229,\n",
       "  0.92313929004612982,\n",
       "  0.92389987037317689,\n",
       "  0.92710667626094256,\n",
       "  0.92737396070203049,\n",
       "  0.92947843419076881,\n",
       "  0.93415244529664165,\n",
       "  0.92698351760744346,\n",
       "  0.93445461004796804,\n",
       "  0.93241416436047353,\n",
       "  0.93704386251614469,\n",
       "  0.9381383625838049,\n",
       "  0.93939485660002131,\n",
       "  0.93915579665620574,\n",
       "  0.93490497571780307,\n",
       "  0.94310778976657772,\n",
       "  0.94167195895800193,\n",
       "  0.94105800312956567,\n",
       "  0.94266230863297618,\n",
       "  0.94150027111611811,\n",
       "  0.94094789883008401,\n",
       "  0.94281561939093361,\n",
       "  0.94275047561274528,\n",
       "  0.94264738861844677,\n",
       "  0.94248117890011351],\n",
       " 'val_loss': [0.20703599260926012,\n",
       "  0.20549562752012654,\n",
       "  0.19647897352521218,\n",
       "  0.19370437611062774,\n",
       "  0.19891810944131877,\n",
       "  0.1868699131815279,\n",
       "  0.17456673718037446,\n",
       "  0.17773872215761885,\n",
       "  0.17714046167249997,\n",
       "  0.16714521592632961,\n",
       "  0.16765546921662591,\n",
       "  0.15963105104995381,\n",
       "  0.15819204848969615,\n",
       "  0.15335739543021076,\n",
       "  0.15592181407398231,\n",
       "  0.15490526446893313,\n",
       "  0.14839422486151599,\n",
       "  0.14796673578222982,\n",
       "  0.14391836055603852,\n",
       "  0.13317152755316677,\n",
       "  0.15088740822608437,\n",
       "  0.13349998850660849,\n",
       "  0.13922441822489492,\n",
       "  0.12868866933352352,\n",
       "  0.12671450067362758,\n",
       "  0.12439499777871639,\n",
       "  0.12543536754862966,\n",
       "  0.13587516847785658,\n",
       "  0.11660845340586365,\n",
       "  0.12051406209970036,\n",
       "  0.12250947802966142,\n",
       "  0.11916962948084346,\n",
       "  0.12187476813324777,\n",
       "  0.1240473218657413,\n",
       "  0.11934716113950977,\n",
       "  0.11935085437328267,\n",
       "  0.11969571115635701,\n",
       "  0.12006334925330224]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:23:37.722460Z",
     "start_time": "2017-09-08T10:23:37.712933Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d_bn(x,\n",
    "              filters,\n",
    "              num_row,\n",
    "              num_col,\n",
    "              padding='same',\n",
    "              strides=(1, 1),\n",
    "              name=None):\n",
    "    \"\"\"Utility function to apply conv + BN.\n",
    "\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        filters: filters in `Conv2D`.\n",
    "        num_row: height of the convolution kernel.\n",
    "        num_col: width of the convolution kernel.\n",
    "        padding: padding mode in `Conv2D`.\n",
    "        strides: strides in `Conv2D`.\n",
    "        name: name of the ops; will become `name + '_conv'`\n",
    "            for the convolution and `name + '_bn'` for the\n",
    "            batch norm layer.\n",
    "\n",
    "    # Returns\n",
    "        Output tensor after applying `Conv2D` and `BatchNormalization`.\n",
    "    \"\"\"\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        bn_axis = 1\n",
    "    else:\n",
    "        bn_axis = 3\n",
    "    x = Conv2D(\n",
    "        filters, (num_row, num_col),\n",
    "        strides=strides,\n",
    "        padding=padding,\n",
    "        use_bias=False,\n",
    "        name=conv_name)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n",
    "    x = Activation('relu', name=name)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:23:38.437884Z",
     "start_time": "2017-09-08T10:23:38.427740Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inception_block(x, nf):\n",
    "    branch1x1 = conv2d_bn(x, int(nf/4), 1, 1)\n",
    "    \n",
    "    branch5x5 = conv2d_bn(x, int(nf*3/16), 1, 1)\n",
    "    branch5x5 = conv2d_bn(branch5x5, int(nf/4), 5, 5)\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, int(nf/4), 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, int(nf*3/8), 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, int(nf*3/8), 3, 3)\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, int(nf/8), 1, 1)\n",
    "\n",
    "    out = concatenate([branch1x1, branch5x5, branch3x3dbl, branch_pool],axis=3)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:23:39.145245Z",
     "start_time": "2017-09-08T10:23:39.141649Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(256,256,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:23:40.096055Z",
     "start_time": "2017-09-08T10:23:39.564071Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "down1 = inception_block(inp, 32)\n",
    "down1 = inception_block(down1, 32)\n",
    "down1_pool = MaxPooling2D((2, 2), strides=(2, 2))(down1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:23:40.560970Z",
     "start_time": "2017-09-08T10:23:40.097869Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "down2 = inception_block(down1_pool, 64)\n",
    "down2 = inception_block(down2, 64)\n",
    "down2_pool = MaxPooling2D((2, 2), strides=(2, 2))(down2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:23:41.115428Z",
     "start_time": "2017-09-08T10:23:40.562518Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "down3 = inception_block(down2_pool, 128)\n",
    "down3 = inception_block(down3, 128)\n",
    "down3_pool = MaxPooling2D((2, 2), strides=(2, 2))(down3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:23:41.557337Z",
     "start_time": "2017-09-08T10:23:41.117079Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "down4 = inception_block(down3_pool, 256)\n",
    "down4 = inception_block(down4, 256)\n",
    "down4_pool = MaxPooling2D((2, 2), strides=(2, 2))(down4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:23:42.105054Z",
     "start_time": "2017-09-08T10:23:41.558643Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "down5 = inception_block(down4_pool, 512)\n",
    "down5 = inception_block(down5, 512)\n",
    "down5_pool = MaxPooling2D((2, 2), strides=(2, 2))(down5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:23:42.569058Z",
     "start_time": "2017-09-08T10:23:42.106481Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "center = inception_block(down5_pool, 1024)\n",
    "center = inception_block(center, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:23:43.165991Z",
     "start_time": "2017-09-08T10:23:42.570811Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "up5 = UpSampling2D((2, 2))(center)\n",
    "up5 = concatenate([down5, up5], axis=3)\n",
    "up5 = inception_block(up5, 512)\n",
    "up5 = inception_block(up5, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:23:43.684052Z",
     "start_time": "2017-09-08T10:23:43.167561Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "up4 = UpSampling2D((2, 2))(up5)\n",
    "up4 = concatenate([down4, up4], axis=3)\n",
    "up4 = inception_block(up4, 256)\n",
    "up4 = inception_block(up4, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:23:44.406132Z",
     "start_time": "2017-09-08T10:23:43.685908Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "up3 = UpSampling2D((2, 2))(up4)\n",
    "up3 = concatenate([down3, up3], axis=3)\n",
    "up3 = inception_block(up3, 128)\n",
    "up3 = inception_block(up3, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:23:44.856702Z",
     "start_time": "2017-09-08T10:23:44.407927Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "up2 = UpSampling2D((2, 2))(up3)\n",
    "up2 = concatenate([down2, up2], axis=3)\n",
    "up2 = inception_block(up2, 64)\n",
    "up2 = inception_block(up2, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:23:45.302773Z",
     "start_time": "2017-09-08T10:23:44.858435Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "up1 = UpSampling2D((2, 2))(up2)\n",
    "up1 = concatenate([down1, up1], axis=3)\n",
    "up1 = inception_block(up1, 32)\n",
    "up1 = inception_block(up1, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:23:45.317407Z",
     "start_time": "2017-09-08T10:23:45.304445Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classify = Conv2D(1, (1, 1), activation='sigmoid')(up1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:23:45.381910Z",
     "start_time": "2017-09-08T10:23:45.318542Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=inp, outputs=classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:23:45.942631Z",
     "start_time": "2017-09-08T10:23:45.770523Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 256, 256, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 256, 256, 8)   24          input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 256, 256, 8)   24          conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 256, 256, 8)   0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 256, 256, 6)   18          input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 256, 256, 12)  864         activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 256, 256, 6)   18          conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 256, 256, 12)  36          conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 256, 256, 6)   0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 256, 256, 12)  0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePool (None, 256, 256, 3)   0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 256, 256, 8)   24          input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 256, 256, 8)   1200        activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 256, 256, 12)  1296        activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 256, 256, 4)   12          average_pooling2d_1[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 256, 256, 8)   24          conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 256, 256, 8)   24          conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 256, 256, 12)  36          conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 256, 256, 4)   12          conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 256, 256, 8)   0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 256, 256, 8)   0           batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 256, 256, 12)  0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 256, 256, 4)   0           batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 256, 256, 32)  0           activation_1[0][0]               \n",
      "                                                                   activation_3[0][0]               \n",
      "                                                                   activation_6[0][0]               \n",
      "                                                                   activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 256, 256, 8)   256         concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, 256, 256, 8)   24          conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 256, 256, 8)   0           batch_normalization_11[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 256, 256, 6)   192         concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, 256, 256, 12)  864         activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, 256, 256, 6)   18          conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, 256, 256, 12)  36          conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 256, 256, 6)   0           batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 256, 256, 12)  0           batch_normalization_12[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePool (None, 256, 256, 32)  0           concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 256, 256, 8)   256         concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 256, 256, 8)   1200        activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, 256, 256, 12)  1296        activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, 256, 256, 4)   128         average_pooling2d_2[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 256, 256, 8)   24          conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, 256, 256, 8)   24          conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNor (None, 256, 256, 12)  36          conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNor (None, 256, 256, 4)   12          conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 256, 256, 8)   0           batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 256, 256, 8)   0           batch_normalization_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 256, 256, 12)  0           batch_normalization_13[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 256, 256, 4)   0           batch_normalization_14[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 256, 256, 32)  0           activation_8[0][0]               \n",
      "                                                                   activation_10[0][0]              \n",
      "                                                                   activation_13[0][0]              \n",
      "                                                                   activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 128, 128, 32)  0           concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)               (None, 128, 128, 16)  512         max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNor (None, 128, 128, 16)  48          conv2d_18[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 128, 128, 16)  0           batch_normalization_18[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, 128, 128, 12)  384         max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, 128, 128, 24)  3456        activation_18[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNor (None, 128, 128, 12)  36          conv2d_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNor (None, 128, 128, 24)  72          conv2d_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, 128, 128, 12)  0           batch_normalization_16[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 128, 128, 24)  0           batch_normalization_19[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePool (None, 128, 128, 32)  0           max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, 128, 128, 16)  512         max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, 128, 128, 16)  4800        activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, 128, 128, 24)  5184        activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)               (None, 128, 128, 8)   256         average_pooling2d_3[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNor (None, 128, 128, 16)  48          conv2d_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNor (None, 128, 128, 16)  48          conv2d_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNor (None, 128, 128, 24)  72          conv2d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNor (None, 128, 128, 8)   24          conv2d_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 128, 128, 16)  0           batch_normalization_15[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 128, 128, 16)  0           batch_normalization_17[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 128, 128, 24)  0           batch_normalization_20[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 128, 128, 8)   0           batch_normalization_21[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 128, 128, 64)  0           activation_15[0][0]              \n",
      "                                                                   activation_17[0][0]              \n",
      "                                                                   activation_20[0][0]              \n",
      "                                                                   activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)               (None, 128, 128, 16)  1024        concatenate_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNor (None, 128, 128, 16)  48          conv2d_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, 128, 128, 16)  0           batch_normalization_25[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, 128, 128, 12)  768         concatenate_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)               (None, 128, 128, 24)  3456        activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNor (None, 128, 128, 12)  36          conv2d_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNor (None, 128, 128, 24)  72          conv2d_26[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 128, 128, 12)  0           batch_normalization_23[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 128, 128, 24)  0           batch_normalization_26[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePool (None, 128, 128, 64)  0           concatenate_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, 128, 128, 16)  1024        concatenate_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)               (None, 128, 128, 16)  4800        activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)               (None, 128, 128, 24)  5184        activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)               (None, 128, 128, 8)   512         average_pooling2d_4[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNor (None, 128, 128, 16)  48          conv2d_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNor (None, 128, 128, 16)  48          conv2d_24[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNor (None, 128, 128, 24)  72          conv2d_27[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNor (None, 128, 128, 8)   24          conv2d_28[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 128, 128, 16)  0           batch_normalization_22[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 128, 128, 16)  0           batch_normalization_24[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, 128, 128, 24)  0           batch_normalization_27[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)       (None, 128, 128, 8)   0           batch_normalization_28[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 128, 128, 64)  0           activation_22[0][0]              \n",
      "                                                                   activation_24[0][0]              \n",
      "                                                                   activation_27[0][0]              \n",
      "                                                                   activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 64, 64, 64)    0           concatenate_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)               (None, 64, 64, 32)    2048        max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNor (None, 64, 64, 32)    96          conv2d_32[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_32 (Activation)       (None, 64, 64, 32)    0           batch_normalization_32[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)               (None, 64, 64, 24)    1536        max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)               (None, 64, 64, 48)    13824       activation_32[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNor (None, 64, 64, 24)    72          conv2d_30[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNor (None, 64, 64, 48)    144         conv2d_33[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_30 (Activation)       (None, 64, 64, 24)    0           batch_normalization_30[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_33 (Activation)       (None, 64, 64, 48)    0           batch_normalization_33[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePool (None, 64, 64, 64)    0           max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)               (None, 64, 64, 32)    2048        max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)               (None, 64, 64, 32)    19200       activation_30[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)               (None, 64, 64, 48)    20736       activation_33[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)               (None, 64, 64, 16)    1024        average_pooling2d_5[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNor (None, 64, 64, 32)    96          conv2d_29[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNor (None, 64, 64, 32)    96          conv2d_31[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNor (None, 64, 64, 48)    144         conv2d_34[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNor (None, 64, 64, 16)    48          conv2d_35[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_29 (Activation)       (None, 64, 64, 32)    0           batch_normalization_29[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_31 (Activation)       (None, 64, 64, 32)    0           batch_normalization_31[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_34 (Activation)       (None, 64, 64, 48)    0           batch_normalization_34[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_35 (Activation)       (None, 64, 64, 16)    0           batch_normalization_35[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)      (None, 64, 64, 128)   0           activation_29[0][0]              \n",
      "                                                                   activation_31[0][0]              \n",
      "                                                                   activation_34[0][0]              \n",
      "                                                                   activation_35[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)               (None, 64, 64, 32)    4096        concatenate_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNor (None, 64, 64, 32)    96          conv2d_39[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_39 (Activation)       (None, 64, 64, 32)    0           batch_normalization_39[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)               (None, 64, 64, 24)    3072        concatenate_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)               (None, 64, 64, 48)    13824       activation_39[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNor (None, 64, 64, 24)    72          conv2d_37[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNor (None, 64, 64, 48)    144         conv2d_40[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_37 (Activation)       (None, 64, 64, 24)    0           batch_normalization_37[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_40 (Activation)       (None, 64, 64, 48)    0           batch_normalization_40[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePool (None, 64, 64, 128)   0           concatenate_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)               (None, 64, 64, 32)    4096        concatenate_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)               (None, 64, 64, 32)    19200       activation_37[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)               (None, 64, 64, 48)    20736       activation_40[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)               (None, 64, 64, 16)    2048        average_pooling2d_6[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNor (None, 64, 64, 32)    96          conv2d_36[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNor (None, 64, 64, 32)    96          conv2d_38[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNor (None, 64, 64, 48)    144         conv2d_41[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNor (None, 64, 64, 16)    48          conv2d_42[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_36 (Activation)       (None, 64, 64, 32)    0           batch_normalization_36[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_38 (Activation)       (None, 64, 64, 32)    0           batch_normalization_38[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_41 (Activation)       (None, 64, 64, 48)    0           batch_normalization_41[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_42 (Activation)       (None, 64, 64, 16)    0           batch_normalization_42[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)      (None, 64, 64, 128)   0           activation_36[0][0]              \n",
      "                                                                   activation_38[0][0]              \n",
      "                                                                   activation_41[0][0]              \n",
      "                                                                   activation_42[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 32, 32, 128)   0           concatenate_6[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)               (None, 32, 32, 64)    8192        max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNor (None, 32, 32, 64)    192         conv2d_46[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_46 (Activation)       (None, 32, 32, 64)    0           batch_normalization_46[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)               (None, 32, 32, 48)    6144        max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)               (None, 32, 32, 96)    55296       activation_46[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNor (None, 32, 32, 48)    144         conv2d_44[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNor (None, 32, 32, 96)    288         conv2d_47[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_44 (Activation)       (None, 32, 32, 48)    0           batch_normalization_44[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_47 (Activation)       (None, 32, 32, 96)    0           batch_normalization_47[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePool (None, 32, 32, 128)   0           max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)               (None, 32, 32, 64)    8192        max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)               (None, 32, 32, 64)    76800       activation_44[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)               (None, 32, 32, 96)    82944       activation_47[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)               (None, 32, 32, 32)    4096        average_pooling2d_7[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNor (None, 32, 32, 64)    192         conv2d_43[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNor (None, 32, 32, 64)    192         conv2d_45[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNor (None, 32, 32, 96)    288         conv2d_48[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNor (None, 32, 32, 32)    96          conv2d_49[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_43 (Activation)       (None, 32, 32, 64)    0           batch_normalization_43[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_45 (Activation)       (None, 32, 32, 64)    0           batch_normalization_45[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_48 (Activation)       (None, 32, 32, 96)    0           batch_normalization_48[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_49 (Activation)       (None, 32, 32, 32)    0           batch_normalization_49[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)      (None, 32, 32, 256)   0           activation_43[0][0]              \n",
      "                                                                   activation_45[0][0]              \n",
      "                                                                   activation_48[0][0]              \n",
      "                                                                   activation_49[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)               (None, 32, 32, 64)    16384       concatenate_7[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNor (None, 32, 32, 64)    192         conv2d_53[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_53 (Activation)       (None, 32, 32, 64)    0           batch_normalization_53[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)               (None, 32, 32, 48)    12288       concatenate_7[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)               (None, 32, 32, 96)    55296       activation_53[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNor (None, 32, 32, 48)    144         conv2d_51[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNor (None, 32, 32, 96)    288         conv2d_54[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_51 (Activation)       (None, 32, 32, 48)    0           batch_normalization_51[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_54 (Activation)       (None, 32, 32, 96)    0           batch_normalization_54[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePool (None, 32, 32, 256)   0           concatenate_7[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)               (None, 32, 32, 64)    16384       concatenate_7[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)               (None, 32, 32, 64)    76800       activation_51[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)               (None, 32, 32, 96)    82944       activation_54[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)               (None, 32, 32, 32)    8192        average_pooling2d_8[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNor (None, 32, 32, 64)    192         conv2d_50[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNor (None, 32, 32, 64)    192         conv2d_52[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNor (None, 32, 32, 96)    288         conv2d_55[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNor (None, 32, 32, 32)    96          conv2d_56[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_50 (Activation)       (None, 32, 32, 64)    0           batch_normalization_50[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_52 (Activation)       (None, 32, 32, 64)    0           batch_normalization_52[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_55 (Activation)       (None, 32, 32, 96)    0           batch_normalization_55[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_56 (Activation)       (None, 32, 32, 32)    0           batch_normalization_56[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)      (None, 32, 32, 256)   0           activation_50[0][0]              \n",
      "                                                                   activation_52[0][0]              \n",
      "                                                                   activation_55[0][0]              \n",
      "                                                                   activation_56[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (None, 16, 16, 256)   0           concatenate_8[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)               (None, 16, 16, 128)   32768       max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNor (None, 16, 16, 128)   384         conv2d_60[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_60 (Activation)       (None, 16, 16, 128)   0           batch_normalization_60[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)               (None, 16, 16, 96)    24576       max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)               (None, 16, 16, 192)   221184      activation_60[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNor (None, 16, 16, 96)    288         conv2d_58[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNor (None, 16, 16, 192)   576         conv2d_61[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_58 (Activation)       (None, 16, 16, 96)    0           batch_normalization_58[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_61 (Activation)       (None, 16, 16, 192)   0           batch_normalization_61[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePool (None, 16, 16, 256)   0           max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)               (None, 16, 16, 128)   32768       max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)               (None, 16, 16, 128)   307200      activation_58[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)               (None, 16, 16, 192)   331776      activation_61[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)               (None, 16, 16, 64)    16384       average_pooling2d_9[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNor (None, 16, 16, 128)   384         conv2d_57[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNor (None, 16, 16, 128)   384         conv2d_59[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNor (None, 16, 16, 192)   576         conv2d_62[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNor (None, 16, 16, 64)    192         conv2d_63[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_57 (Activation)       (None, 16, 16, 128)   0           batch_normalization_57[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_59 (Activation)       (None, 16, 16, 128)   0           batch_normalization_59[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_62 (Activation)       (None, 16, 16, 192)   0           batch_normalization_62[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_63 (Activation)       (None, 16, 16, 64)    0           batch_normalization_63[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)      (None, 16, 16, 512)   0           activation_57[0][0]              \n",
      "                                                                   activation_59[0][0]              \n",
      "                                                                   activation_62[0][0]              \n",
      "                                                                   activation_63[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)               (None, 16, 16, 128)   65536       concatenate_9[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNor (None, 16, 16, 128)   384         conv2d_67[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_67 (Activation)       (None, 16, 16, 128)   0           batch_normalization_67[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)               (None, 16, 16, 96)    49152       concatenate_9[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)               (None, 16, 16, 192)   221184      activation_67[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNor (None, 16, 16, 96)    288         conv2d_65[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNor (None, 16, 16, 192)   576         conv2d_68[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_65 (Activation)       (None, 16, 16, 96)    0           batch_normalization_65[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_68 (Activation)       (None, 16, 16, 192)   0           batch_normalization_68[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePoo (None, 16, 16, 512)   0           concatenate_9[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)               (None, 16, 16, 128)   65536       concatenate_9[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)               (None, 16, 16, 128)   307200      activation_65[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)               (None, 16, 16, 192)   331776      activation_68[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)               (None, 16, 16, 64)    32768       average_pooling2d_10[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNor (None, 16, 16, 128)   384         conv2d_64[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNor (None, 16, 16, 128)   384         conv2d_66[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNor (None, 16, 16, 192)   576         conv2d_69[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNor (None, 16, 16, 64)    192         conv2d_70[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_64 (Activation)       (None, 16, 16, 128)   0           batch_normalization_64[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_66 (Activation)       (None, 16, 16, 128)   0           batch_normalization_66[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_69 (Activation)       (None, 16, 16, 192)   0           batch_normalization_69[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_70 (Activation)       (None, 16, 16, 64)    0           batch_normalization_70[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)     (None, 16, 16, 512)   0           activation_64[0][0]              \n",
      "                                                                   activation_66[0][0]              \n",
      "                                                                   activation_69[0][0]              \n",
      "                                                                   activation_70[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)   (None, 8, 8, 512)     0           concatenate_10[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)               (None, 8, 8, 256)     131072      max_pooling2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNor (None, 8, 8, 256)     768         conv2d_74[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_74 (Activation)       (None, 8, 8, 256)     0           batch_normalization_74[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)               (None, 8, 8, 192)     98304       max_pooling2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)               (None, 8, 8, 384)     884736      activation_74[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNor (None, 8, 8, 192)     576         conv2d_72[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNor (None, 8, 8, 384)     1152        conv2d_75[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_72 (Activation)       (None, 8, 8, 192)     0           batch_normalization_72[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_75 (Activation)       (None, 8, 8, 384)     0           batch_normalization_75[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePoo (None, 8, 8, 512)     0           max_pooling2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)               (None, 8, 8, 256)     131072      max_pooling2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)               (None, 8, 8, 256)     1228800     activation_72[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)               (None, 8, 8, 384)     1327104     activation_75[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)               (None, 8, 8, 128)     65536       average_pooling2d_11[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNor (None, 8, 8, 256)     768         conv2d_71[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNor (None, 8, 8, 256)     768         conv2d_73[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNor (None, 8, 8, 384)     1152        conv2d_76[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNor (None, 8, 8, 128)     384         conv2d_77[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_71 (Activation)       (None, 8, 8, 256)     0           batch_normalization_71[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_73 (Activation)       (None, 8, 8, 256)     0           batch_normalization_73[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_76 (Activation)       (None, 8, 8, 384)     0           batch_normalization_76[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_77 (Activation)       (None, 8, 8, 128)     0           batch_normalization_77[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)     (None, 8, 8, 1024)    0           activation_71[0][0]              \n",
      "                                                                   activation_73[0][0]              \n",
      "                                                                   activation_76[0][0]              \n",
      "                                                                   activation_77[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)               (None, 8, 8, 256)     262144      concatenate_11[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNor (None, 8, 8, 256)     768         conv2d_81[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_81 (Activation)       (None, 8, 8, 256)     0           batch_normalization_81[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)               (None, 8, 8, 192)     196608      concatenate_11[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)               (None, 8, 8, 384)     884736      activation_81[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNor (None, 8, 8, 192)     576         conv2d_79[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNor (None, 8, 8, 384)     1152        conv2d_82[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_79 (Activation)       (None, 8, 8, 192)     0           batch_normalization_79[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_82 (Activation)       (None, 8, 8, 384)     0           batch_normalization_82[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePoo (None, 8, 8, 1024)    0           concatenate_11[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)               (None, 8, 8, 256)     262144      concatenate_11[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)               (None, 8, 8, 256)     1228800     activation_79[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)               (None, 8, 8, 384)     1327104     activation_82[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)               (None, 8, 8, 128)     131072      average_pooling2d_12[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNor (None, 8, 8, 256)     768         conv2d_78[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNor (None, 8, 8, 256)     768         conv2d_80[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNor (None, 8, 8, 384)     1152        conv2d_83[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNor (None, 8, 8, 128)     384         conv2d_84[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_78 (Activation)       (None, 8, 8, 256)     0           batch_normalization_78[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_80 (Activation)       (None, 8, 8, 256)     0           batch_normalization_80[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_83 (Activation)       (None, 8, 8, 384)     0           batch_normalization_83[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_84 (Activation)       (None, 8, 8, 128)     0           batch_normalization_84[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)     (None, 8, 8, 1024)    0           activation_78[0][0]              \n",
      "                                                                   activation_80[0][0]              \n",
      "                                                                   activation_83[0][0]              \n",
      "                                                                   activation_84[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)   (None, 16, 16, 1024)  0           concatenate_12[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)     (None, 16, 16, 1536)  0           concatenate_10[0][0]             \n",
      "                                                                   up_sampling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)               (None, 16, 16, 128)   196608      concatenate_13[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNor (None, 16, 16, 128)   384         conv2d_88[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_88 (Activation)       (None, 16, 16, 128)   0           batch_normalization_88[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)               (None, 16, 16, 96)    147456      concatenate_13[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)               (None, 16, 16, 192)   221184      activation_88[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNor (None, 16, 16, 96)    288         conv2d_86[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNor (None, 16, 16, 192)   576         conv2d_89[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_86 (Activation)       (None, 16, 16, 96)    0           batch_normalization_86[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_89 (Activation)       (None, 16, 16, 192)   0           batch_normalization_89[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePoo (None, 16, 16, 1536)  0           concatenate_13[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)               (None, 16, 16, 128)   196608      concatenate_13[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)               (None, 16, 16, 128)   307200      activation_86[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)               (None, 16, 16, 192)   331776      activation_89[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)               (None, 16, 16, 64)    98304       average_pooling2d_13[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNor (None, 16, 16, 128)   384         conv2d_85[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNor (None, 16, 16, 128)   384         conv2d_87[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNor (None, 16, 16, 192)   576         conv2d_90[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNor (None, 16, 16, 64)    192         conv2d_91[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_85 (Activation)       (None, 16, 16, 128)   0           batch_normalization_85[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_87 (Activation)       (None, 16, 16, 128)   0           batch_normalization_87[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_90 (Activation)       (None, 16, 16, 192)   0           batch_normalization_90[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_91 (Activation)       (None, 16, 16, 64)    0           batch_normalization_91[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)     (None, 16, 16, 512)   0           activation_85[0][0]              \n",
      "                                                                   activation_87[0][0]              \n",
      "                                                                   activation_90[0][0]              \n",
      "                                                                   activation_91[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)               (None, 16, 16, 128)   65536       concatenate_14[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNor (None, 16, 16, 128)   384         conv2d_95[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_95 (Activation)       (None, 16, 16, 128)   0           batch_normalization_95[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)               (None, 16, 16, 96)    49152       concatenate_14[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)               (None, 16, 16, 192)   221184      activation_95[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNor (None, 16, 16, 96)    288         conv2d_93[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNor (None, 16, 16, 192)   576         conv2d_96[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_93 (Activation)       (None, 16, 16, 96)    0           batch_normalization_93[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_96 (Activation)       (None, 16, 16, 192)   0           batch_normalization_96[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePoo (None, 16, 16, 512)   0           concatenate_14[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)               (None, 16, 16, 128)   65536       concatenate_14[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)               (None, 16, 16, 128)   307200      activation_93[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)               (None, 16, 16, 192)   331776      activation_96[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)               (None, 16, 16, 64)    32768       average_pooling2d_14[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNor (None, 16, 16, 128)   384         conv2d_92[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNor (None, 16, 16, 128)   384         conv2d_94[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNor (None, 16, 16, 192)   576         conv2d_97[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNor (None, 16, 16, 64)    192         conv2d_98[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_92 (Activation)       (None, 16, 16, 128)   0           batch_normalization_92[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_94 (Activation)       (None, 16, 16, 128)   0           batch_normalization_94[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_97 (Activation)       (None, 16, 16, 192)   0           batch_normalization_97[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_98 (Activation)       (None, 16, 16, 64)    0           batch_normalization_98[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)     (None, 16, 16, 512)   0           activation_92[0][0]              \n",
      "                                                                   activation_94[0][0]              \n",
      "                                                                   activation_97[0][0]              \n",
      "                                                                   activation_98[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)   (None, 32, 32, 512)   0           concatenate_15[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)     (None, 32, 32, 768)   0           concatenate_8[0][0]              \n",
      "                                                                   up_sampling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)              (None, 32, 32, 64)    49152       concatenate_16[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchNo (None, 32, 32, 64)    192         conv2d_102[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_102 (Activation)      (None, 32, 32, 64)    0           batch_normalization_102[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)              (None, 32, 32, 48)    36864       concatenate_16[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)              (None, 32, 32, 96)    55296       activation_102[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchNo (None, 32, 32, 48)    144         conv2d_100[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchNo (None, 32, 32, 96)    288         conv2d_103[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_100 (Activation)      (None, 32, 32, 48)    0           batch_normalization_100[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_103 (Activation)      (None, 32, 32, 96)    0           batch_normalization_103[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePoo (None, 32, 32, 768)   0           concatenate_16[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)               (None, 32, 32, 64)    49152       concatenate_16[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)              (None, 32, 32, 64)    76800       activation_100[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)              (None, 32, 32, 96)    82944       activation_103[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)              (None, 32, 32, 32)    24576       average_pooling2d_15[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNor (None, 32, 32, 64)    192         conv2d_99[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchNo (None, 32, 32, 64)    192         conv2d_101[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchNo (None, 32, 32, 96)    288         conv2d_104[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchNo (None, 32, 32, 32)    96          conv2d_105[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_99 (Activation)       (None, 32, 32, 64)    0           batch_normalization_99[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_101 (Activation)      (None, 32, 32, 64)    0           batch_normalization_101[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_104 (Activation)      (None, 32, 32, 96)    0           batch_normalization_104[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_105 (Activation)      (None, 32, 32, 32)    0           batch_normalization_105[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)     (None, 32, 32, 256)   0           activation_99[0][0]              \n",
      "                                                                   activation_101[0][0]             \n",
      "                                                                   activation_104[0][0]             \n",
      "                                                                   activation_105[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)              (None, 32, 32, 64)    16384       concatenate_17[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchNo (None, 32, 32, 64)    192         conv2d_109[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_109 (Activation)      (None, 32, 32, 64)    0           batch_normalization_109[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)              (None, 32, 32, 48)    12288       concatenate_17[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)              (None, 32, 32, 96)    55296       activation_109[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchNo (None, 32, 32, 48)    144         conv2d_107[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchNo (None, 32, 32, 96)    288         conv2d_110[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_107 (Activation)      (None, 32, 32, 48)    0           batch_normalization_107[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_110 (Activation)      (None, 32, 32, 96)    0           batch_normalization_110[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePoo (None, 32, 32, 256)   0           concatenate_17[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)              (None, 32, 32, 64)    16384       concatenate_17[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)              (None, 32, 32, 64)    76800       activation_107[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)              (None, 32, 32, 96)    82944       activation_110[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)              (None, 32, 32, 32)    8192        average_pooling2d_16[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchNo (None, 32, 32, 64)    192         conv2d_106[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchNo (None, 32, 32, 64)    192         conv2d_108[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchNo (None, 32, 32, 96)    288         conv2d_111[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchNo (None, 32, 32, 32)    96          conv2d_112[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_106 (Activation)      (None, 32, 32, 64)    0           batch_normalization_106[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_108 (Activation)      (None, 32, 32, 64)    0           batch_normalization_108[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_111 (Activation)      (None, 32, 32, 96)    0           batch_normalization_111[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_112 (Activation)      (None, 32, 32, 32)    0           batch_normalization_112[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)     (None, 32, 32, 256)   0           activation_106[0][0]             \n",
      "                                                                   activation_108[0][0]             \n",
      "                                                                   activation_111[0][0]             \n",
      "                                                                   activation_112[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)   (None, 64, 64, 256)   0           concatenate_18[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)     (None, 64, 64, 384)   0           concatenate_6[0][0]              \n",
      "                                                                   up_sampling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)              (None, 64, 64, 32)    12288       concatenate_19[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchNo (None, 64, 64, 32)    96          conv2d_116[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_116 (Activation)      (None, 64, 64, 32)    0           batch_normalization_116[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)              (None, 64, 64, 24)    9216        concatenate_19[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)              (None, 64, 64, 48)    13824       activation_116[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchNo (None, 64, 64, 24)    72          conv2d_114[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchNo (None, 64, 64, 48)    144         conv2d_117[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_114 (Activation)      (None, 64, 64, 24)    0           batch_normalization_114[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_117 (Activation)      (None, 64, 64, 48)    0           batch_normalization_117[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePoo (None, 64, 64, 384)   0           concatenate_19[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)              (None, 64, 64, 32)    12288       concatenate_19[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)              (None, 64, 64, 32)    19200       activation_114[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)              (None, 64, 64, 48)    20736       activation_117[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)              (None, 64, 64, 16)    6144        average_pooling2d_17[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchNo (None, 64, 64, 32)    96          conv2d_113[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchNo (None, 64, 64, 32)    96          conv2d_115[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchNo (None, 64, 64, 48)    144         conv2d_118[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchNo (None, 64, 64, 16)    48          conv2d_119[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_113 (Activation)      (None, 64, 64, 32)    0           batch_normalization_113[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_115 (Activation)      (None, 64, 64, 32)    0           batch_normalization_115[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_118 (Activation)      (None, 64, 64, 48)    0           batch_normalization_118[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_119 (Activation)      (None, 64, 64, 16)    0           batch_normalization_119[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)     (None, 64, 64, 128)   0           activation_113[0][0]             \n",
      "                                                                   activation_115[0][0]             \n",
      "                                                                   activation_118[0][0]             \n",
      "                                                                   activation_119[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)              (None, 64, 64, 32)    4096        concatenate_20[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchNo (None, 64, 64, 32)    96          conv2d_123[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_123 (Activation)      (None, 64, 64, 32)    0           batch_normalization_123[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)              (None, 64, 64, 24)    3072        concatenate_20[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)              (None, 64, 64, 48)    13824       activation_123[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchNo (None, 64, 64, 24)    72          conv2d_121[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchNo (None, 64, 64, 48)    144         conv2d_124[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_121 (Activation)      (None, 64, 64, 24)    0           batch_normalization_121[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_124 (Activation)      (None, 64, 64, 48)    0           batch_normalization_124[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePoo (None, 64, 64, 128)   0           concatenate_20[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)              (None, 64, 64, 32)    4096        concatenate_20[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)              (None, 64, 64, 32)    19200       activation_121[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)              (None, 64, 64, 48)    20736       activation_124[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)              (None, 64, 64, 16)    2048        average_pooling2d_18[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchNo (None, 64, 64, 32)    96          conv2d_120[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchNo (None, 64, 64, 32)    96          conv2d_122[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchNo (None, 64, 64, 48)    144         conv2d_125[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchNo (None, 64, 64, 16)    48          conv2d_126[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_120 (Activation)      (None, 64, 64, 32)    0           batch_normalization_120[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_122 (Activation)      (None, 64, 64, 32)    0           batch_normalization_122[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_125 (Activation)      (None, 64, 64, 48)    0           batch_normalization_125[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_126 (Activation)      (None, 64, 64, 16)    0           batch_normalization_126[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)     (None, 64, 64, 128)   0           activation_120[0][0]             \n",
      "                                                                   activation_122[0][0]             \n",
      "                                                                   activation_125[0][0]             \n",
      "                                                                   activation_126[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)   (None, 128, 128, 128) 0           concatenate_21[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)     (None, 128, 128, 192) 0           concatenate_4[0][0]              \n",
      "                                                                   up_sampling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)              (None, 128, 128, 16)  3072        concatenate_22[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchNo (None, 128, 128, 16)  48          conv2d_130[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_130 (Activation)      (None, 128, 128, 16)  0           batch_normalization_130[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)              (None, 128, 128, 12)  2304        concatenate_22[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)              (None, 128, 128, 24)  3456        activation_130[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchNo (None, 128, 128, 12)  36          conv2d_128[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchNo (None, 128, 128, 24)  72          conv2d_131[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_128 (Activation)      (None, 128, 128, 12)  0           batch_normalization_128[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_131 (Activation)      (None, 128, 128, 24)  0           batch_normalization_131[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePoo (None, 128, 128, 192) 0           concatenate_22[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)              (None, 128, 128, 16)  3072        concatenate_22[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)              (None, 128, 128, 16)  4800        activation_128[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)              (None, 128, 128, 24)  5184        activation_131[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)              (None, 128, 128, 8)   1536        average_pooling2d_19[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchNo (None, 128, 128, 16)  48          conv2d_127[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchNo (None, 128, 128, 16)  48          conv2d_129[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchNo (None, 128, 128, 24)  72          conv2d_132[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchNo (None, 128, 128, 8)   24          conv2d_133[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_127 (Activation)      (None, 128, 128, 16)  0           batch_normalization_127[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_129 (Activation)      (None, 128, 128, 16)  0           batch_normalization_129[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_132 (Activation)      (None, 128, 128, 24)  0           batch_normalization_132[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_133 (Activation)      (None, 128, 128, 8)   0           batch_normalization_133[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)     (None, 128, 128, 64)  0           activation_127[0][0]             \n",
      "                                                                   activation_129[0][0]             \n",
      "                                                                   activation_132[0][0]             \n",
      "                                                                   activation_133[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)              (None, 128, 128, 16)  1024        concatenate_23[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchNo (None, 128, 128, 16)  48          conv2d_137[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_137 (Activation)      (None, 128, 128, 16)  0           batch_normalization_137[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)              (None, 128, 128, 12)  768         concatenate_23[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)              (None, 128, 128, 24)  3456        activation_137[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchNo (None, 128, 128, 12)  36          conv2d_135[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchNo (None, 128, 128, 24)  72          conv2d_138[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_135 (Activation)      (None, 128, 128, 12)  0           batch_normalization_135[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_138 (Activation)      (None, 128, 128, 24)  0           batch_normalization_138[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePoo (None, 128, 128, 64)  0           concatenate_23[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)              (None, 128, 128, 16)  1024        concatenate_23[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)              (None, 128, 128, 16)  4800        activation_135[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)              (None, 128, 128, 24)  5184        activation_138[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)              (None, 128, 128, 8)   512         average_pooling2d_20[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchNo (None, 128, 128, 16)  48          conv2d_134[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchNo (None, 128, 128, 16)  48          conv2d_136[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchNo (None, 128, 128, 24)  72          conv2d_139[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchNo (None, 128, 128, 8)   24          conv2d_140[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_134 (Activation)      (None, 128, 128, 16)  0           batch_normalization_134[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_136 (Activation)      (None, 128, 128, 16)  0           batch_normalization_136[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_139 (Activation)      (None, 128, 128, 24)  0           batch_normalization_139[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_140 (Activation)      (None, 128, 128, 8)   0           batch_normalization_140[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)     (None, 128, 128, 64)  0           activation_134[0][0]             \n",
      "                                                                   activation_136[0][0]             \n",
      "                                                                   activation_139[0][0]             \n",
      "                                                                   activation_140[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)   (None, 256, 256, 64)  0           concatenate_24[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)     (None, 256, 256, 96)  0           concatenate_2[0][0]              \n",
      "                                                                   up_sampling2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)              (None, 256, 256, 8)   768         concatenate_25[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchNo (None, 256, 256, 8)   24          conv2d_144[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_144 (Activation)      (None, 256, 256, 8)   0           batch_normalization_144[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)              (None, 256, 256, 6)   576         concatenate_25[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)              (None, 256, 256, 12)  864         activation_144[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchNo (None, 256, 256, 6)   18          conv2d_142[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchNo (None, 256, 256, 12)  36          conv2d_145[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_142 (Activation)      (None, 256, 256, 6)   0           batch_normalization_142[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_145 (Activation)      (None, 256, 256, 12)  0           batch_normalization_145[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePoo (None, 256, 256, 96)  0           concatenate_25[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)              (None, 256, 256, 8)   768         concatenate_25[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)              (None, 256, 256, 8)   1200        activation_142[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)              (None, 256, 256, 12)  1296        activation_145[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)              (None, 256, 256, 4)   384         average_pooling2d_21[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchNo (None, 256, 256, 8)   24          conv2d_141[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchNo (None, 256, 256, 8)   24          conv2d_143[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchNo (None, 256, 256, 12)  36          conv2d_146[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchNo (None, 256, 256, 4)   12          conv2d_147[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_141 (Activation)      (None, 256, 256, 8)   0           batch_normalization_141[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_143 (Activation)      (None, 256, 256, 8)   0           batch_normalization_143[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_146 (Activation)      (None, 256, 256, 12)  0           batch_normalization_146[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_147 (Activation)      (None, 256, 256, 4)   0           batch_normalization_147[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)     (None, 256, 256, 32)  0           activation_141[0][0]             \n",
      "                                                                   activation_143[0][0]             \n",
      "                                                                   activation_146[0][0]             \n",
      "                                                                   activation_147[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)              (None, 256, 256, 8)   256         concatenate_26[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchNo (None, 256, 256, 8)   24          conv2d_151[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_151 (Activation)      (None, 256, 256, 8)   0           batch_normalization_151[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)              (None, 256, 256, 6)   192         concatenate_26[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)              (None, 256, 256, 12)  864         activation_151[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchNo (None, 256, 256, 6)   18          conv2d_149[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchNo (None, 256, 256, 12)  36          conv2d_152[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_149 (Activation)      (None, 256, 256, 6)   0           batch_normalization_149[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_152 (Activation)      (None, 256, 256, 12)  0           batch_normalization_152[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePoo (None, 256, 256, 32)  0           concatenate_26[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)              (None, 256, 256, 8)   256         concatenate_26[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)              (None, 256, 256, 8)   1200        activation_149[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)              (None, 256, 256, 12)  1296        activation_152[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)              (None, 256, 256, 4)   128         average_pooling2d_22[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchNo (None, 256, 256, 8)   24          conv2d_148[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchNo (None, 256, 256, 8)   24          conv2d_150[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchNo (None, 256, 256, 12)  36          conv2d_153[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchNo (None, 256, 256, 4)   12          conv2d_154[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_148 (Activation)      (None, 256, 256, 8)   0           batch_normalization_148[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_150 (Activation)      (None, 256, 256, 8)   0           batch_normalization_150[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_153 (Activation)      (None, 256, 256, 12)  0           batch_normalization_153[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_154 (Activation)      (None, 256, 256, 4)   0           batch_normalization_154[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)     (None, 256, 256, 32)  0           activation_148[0][0]             \n",
      "                                                                   activation_150[0][0]             \n",
      "                                                                   activation_153[0][0]             \n",
      "                                                                   activation_154[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)              (None, 256, 256, 1)   33          concatenate_27[0][0]             \n",
      "====================================================================================================\n",
      "Total params: 14,335,095\n",
      "Trainable params: 14,313,287\n",
      "Non-trainable params: 21,808\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:24:10.056569Z",
     "start_time": "2017-09-08T10:23:46.940971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='model.png' target='_blank'>model.png</a><br>"
      ],
      "text/plain": [
       "/home/sainath/extvol/kaggle-carvana-image-masking-challenge/model.png"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import plot_model  \n",
    "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)  \n",
    "from IPython.display import FileLink\n",
    "FileLink('model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:24:29.243977Z",
     "start_time": "2017-09-08T10:24:29.239955Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size = 256\n",
    "max_epochs = 50\n",
    "train_batch_size = 16\n",
    "val_batch_size=32\n",
    "orig_width = 1918\n",
    "orig_height= 1280\n",
    "threshold  = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:24:39.869192Z",
     "start_time": "2017-09-08T10:24:39.295561Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train_masks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:24:54.034444Z",
     "start_time": "2017-09-08T10:24:54.028619Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids_train = df_train['img'].map(lambda s: s.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:25:03.920028Z",
     "start_time": "2017-09-08T10:25:03.855095Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids_train_split, ids_valid_split = train_test_split(ids_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:28:10.756825Z",
     "start_time": "2017-09-08T10:25:21.102057Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_imgs  = {}\n",
    "all_masks = {}\n",
    "for id in ids_train:\n",
    "    img  = cv2.imread('data/train/{}.jpg'.format(id))\n",
    "    img  = cv2.resize(img, (input_size, input_size))\n",
    "    mask = cv2.imread('data/train_masks/{}_mask.png'.format(id), cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.resize(mask, (input_size, input_size))\n",
    "    all_imgs[id]  = img\n",
    "    all_masks[id] = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-08T10:29:02.134129Z",
     "start_time": "2017-09-08T10:29:02.073404Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=RMSprop(lr=0.0001), loss=bce_dice_loss, metrics=[dice_coeff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-08T10:29:04.633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1193s - loss: 0.6007 - dice_coeff: 0.6648 - val_loss: 1.3479 - val_dice_coeff: 0.1840\n",
      "Epoch 2/50\n",
      "1138s - loss: 0.2524 - dice_coeff: 0.8392 - val_loss: 0.2122 - val_dice_coeff: 0.8652\n",
      "Epoch 4/50\n",
      "1138s - loss: 0.1893 - dice_coeff: 0.8781 - val_loss: 0.1624 - val_dice_coeff: 0.8956\n",
      "Epoch 5/50\n",
      "1138s - loss: 0.1422 - dice_coeff: 0.9082 - val_loss: 0.1286 - val_dice_coeff: 0.9208\n",
      "Epoch 6/50\n",
      "1138s - loss: 0.1072 - dice_coeff: 0.9312 - val_loss: 0.0922 - val_dice_coeff: 0.9409\n",
      "Epoch 7/50\n",
      "1138s - loss: 0.0818 - dice_coeff: 0.9481 - val_loss: 0.0679 - val_dice_coeff: 0.9572\n",
      "Epoch 8/50\n",
      "1138s - loss: 0.0631 - dice_coeff: 0.9607 - val_loss: 0.0547 - val_dice_coeff: 0.9667\n",
      "Epoch 9/50\n",
      "1138s - loss: 0.0499 - dice_coeff: 0.9697 - val_loss: 0.0442 - val_dice_coeff: 0.9737\n",
      "Epoch 10/50\n",
      "1138s - loss: 0.0409 - dice_coeff: 0.9760 - val_loss: 0.0348 - val_dice_coeff: 0.9796\n",
      "Epoch 11/50\n",
      "1138s - loss: 0.0346 - dice_coeff: 0.9803 - val_loss: 0.0293 - val_dice_coeff: 0.9834\n",
      "Epoch 12/50\n",
      "1138s - loss: 0.0302 - dice_coeff: 0.9832 - val_loss: 0.0265 - val_dice_coeff: 0.9854\n",
      "Epoch 13/50\n",
      "1138s - loss: 0.0271 - dice_coeff: 0.9853 - val_loss: 0.0243 - val_dice_coeff: 0.9868\n",
      "Epoch 14/50\n",
      "1138s - loss: 0.0252 - dice_coeff: 0.9866 - val_loss: 0.0212 - val_dice_coeff: 0.9885\n",
      "Epoch 15/50\n",
      "1137s - loss: 0.0236 - dice_coeff: 0.9876 - val_loss: 0.0228 - val_dice_coeff: 0.9881\n",
      "Epoch 16/50\n",
      "1138s - loss: 0.0226 - dice_coeff: 0.9882 - val_loss: 0.0195 - val_dice_coeff: 0.9897\n",
      "Epoch 17/50\n",
      "1137s - loss: 0.0219 - dice_coeff: 0.9886 - val_loss: 0.0233 - val_dice_coeff: 0.9881\n",
      "Epoch 18/50\n",
      "1138s - loss: 0.0211 - dice_coeff: 0.9891 - val_loss: 0.0183 - val_dice_coeff: 0.9903\n",
      "Epoch 19/50\n",
      "1138s - loss: 0.0206 - dice_coeff: 0.9893 - val_loss: 0.0179 - val_dice_coeff: 0.9905\n",
      "Epoch 20/50\n",
      "1137s - loss: 0.0202 - dice_coeff: 0.9895 - val_loss: 0.0190 - val_dice_coeff: 0.9902\n",
      "Epoch 21/50\n",
      "1137s - loss: 0.0199 - dice_coeff: 0.9897 - val_loss: 0.0207 - val_dice_coeff: 0.9895\n",
      "Epoch 22/50\n",
      "1137s - loss: 0.0198 - dice_coeff: 0.9898 - val_loss: 0.0198 - val_dice_coeff: 0.9898\n",
      "Epoch 23/50\n",
      "1138s - loss: 0.0193 - dice_coeff: 0.9900 - val_loss: 0.0170 - val_dice_coeff: 0.9909\n",
      "Epoch 24/50\n",
      "1137s - loss: 0.0189 - dice_coeff: 0.9902 - val_loss: 0.0183 - val_dice_coeff: 0.9906\n",
      "Epoch 25/50\n",
      "1137s - loss: 0.0187 - dice_coeff: 0.9903 - val_loss: 0.0176 - val_dice_coeff: 0.9909\n",
      "Epoch 26/50\n",
      "1139s - loss: 0.0184 - dice_coeff: 0.9905 - val_loss: 0.0163 - val_dice_coeff: 0.9915\n",
      "Epoch 27/50\n",
      "1139s - loss: 0.0182 - dice_coeff: 0.9906 - val_loss: 0.0168 - val_dice_coeff: 0.9913\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-b3fcf0eeb002>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                     validation_steps=np.ceil(float(len(ids_valid_split)) / float(val_batch_size)))\n\u001b[0m",
      "\u001b[0;32m/home/sainath/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sainath/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2041\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sainath/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sainath/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sainath/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sainath/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sainath/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sainath/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sainath/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_dice_coeff',\n",
    "                           patience=8,\n",
    "                           verbose=1,\n",
    "                           min_delta=1e-4,\n",
    "                           mode='max'),\n",
    "             ReduceLROnPlateau(monitor='val_dice_coeff',\n",
    "                               factor=0.1,\n",
    "                               patience=4,\n",
    "                               verbose=1,\n",
    "                               epsilon=1e-4,\n",
    "                               mode='max'),\n",
    "             ModelCheckpoint(monitor='val_dice_coeff',\n",
    "                             filepath='weights/unet-inception-256.hdf5',\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             mode='max')]\n",
    "\n",
    "history = model.fit_generator(generator=train_generator(train_batch_size),\n",
    "                    steps_per_epoch=np.ceil(float(len(ids_train_split)) / float(train_batch_size)),\n",
    "                    epochs=max_epochs,\n",
    "                    verbose=2,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=valid_generator(val_batch_size),\n",
    "                    validation_steps=np.ceil(float(len(ids_valid_split)) / float(val_batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
